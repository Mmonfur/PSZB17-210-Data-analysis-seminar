---
title: "Exercise 11"
author: "Zoltan Kekecs"
date: "15 november 2018"
output:
  html_document: default
  pdf_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T, tidy.opts=list(width.cutoff=60), tidy=TRUE)
```

# Exercise 11 - The basics of linear regression

This exercise is related to learning the basic logic behind making predictions with linear regression models, and to quantifying the effectiveness of our predictions.

The latest version of this document and the code the document refers to can be found in the GitHub repository of the class at:
https://github.com/kekecsz/PSYP13_Data_analysis_class-2018


## Loading packages

You will need to load the following packages for this exercise:

```{r packages, message=FALSE}
library(psych) # for describe
library(dplyr) # for data management
library(gsheet) # to read data from google sheets
library(ggplot2) # for ggplot
```

## Custom functions

The following custom functions will come in handy during the visualization of the error of the predictions of the regressions line.
This is not essential for the analysis and you don't need to learn how this custom function works if you don't want to. 

```{r custom function}


error_plotter <- function(mod, col = "black", x_var = NULL){
  mod_vars = as.character(mod$call[2])
  data = eval(parse(text = as.character(mod$call[3])))
  y = substr(mod_vars, 1, as.numeric(gregexpr(pattern ='~',mod_vars))-2)
  x = substr(mod_vars, as.numeric(gregexpr(pattern ='~',mod_vars))+2, nchar(mod_vars))
  
  data$pred = predict(mod)
  
  if(x == "1" & is.null(x_var)){x = "response_ID"
  data$response_ID = 1:nrow(data)} else if(x == "1"){x = x_var}
  
  plot(data[,y] ~ data[,x], ylab = y, xlab = x)
  abline(mod)
  
  for(i in 1:nrow(data)){
    clip(min(data[,x]), max(data[,x]), min(data[i,c(y,"pred")]), max(data[i,c(y,"pred")]))
    abline(v = data[i,x], lty = 2, col = col)
  }
  
}
```

## Data management and descriptive statistics

### Collect some data

Lets say we are a company that sells shoes, and we would like to be able to tell people's shoe size just by knowing their height.
We collect some data using this simple survey:

https://goo.gl/forms/nNXWwCPTbdHxGrBO2

You can load the data we just collected with the following code

```{r load data, message=FALSE}
# data from https://github.com/kekecsz/PSYP13_Data_analysis_class-2018/blob/master/Shoe%20and%20height%20data%20PSYP13-HT18.csv
mydata = as.data.frame(gsheet2tbl("https://docs.google.com/spreadsheets/d/1C07SRvPJzftZaFApiI5YgptyymvyYQpIUi9v6gFbLHw/edit?usp=sharing"))
```

### Check the dataset for irregularities

You should always check the dataset for coding errors or data that does not make sense.

View data in the data viewer tool 
```{r view data, eval=FALSE}
View(mydata)
```

or display simple descriptive statistics and plots.

You can use the describe() function from the psych package for continuous data, and the table() function for categorical data.

```{r check data, eval = F}
describe(mydata$height)
hist(mydata$height, breaks = 20)

describe(mydata$shoe_size)
hist(mydata$shoe_size, breaks = 10)

# scatterplot
plot(shoe_size ~ height, data = mydata)
```

There are several irregularties in the variable 'gender'. We need to handle these before going forward.

```{r check data 2}
table(mydata$gender)
```

You should clean your data before doing the analyses.
Make sure to keep a record of the corrections. You should keep the raw datafile when possible, and make changes in the code, so the corrections and omissions are trackable in your code.

```{r cleaning data}
mydata_cleaned = mydata # create a copy of the data where which will be cleaned


mydata_cleaned[mydata_cleaned[,"height"] == "168cm", "height"] = 168
mydata_cleaned[,"height"] = as.numeric(as.character(mydata_cleaned[,"height"]))
mydata_cleaned[mydata_cleaned[,"height"] == 64, "height"] = 164

describe(mydata_cleaned[,"height"])

mydata_cleaned = mydata_cleaned[-which(mydata_cleaned[,"gender"] == "etc."),] # exclude invalid value
# this code might be required to correct the dataframe as well if you have a cell where "female" has a space after it.
# mydata_cleaned[,"gender"][mydata_cleaned[,"gender"] == "female "] = "female" # unify different coding variations
mydata_cleaned[mydata_cleaned[,"gender"] == "Female", "gender"] = "female"
mydata_cleaned[mydata_cleaned[,"gender"] == "Male", "gender"] = "male"
mydata_cleaned[,"gender"] = factor(mydata_cleaned[,"gender"])
mydata_cleaned[,"gender"] = droplevels(mydata_cleaned[,"gender"]) # if the variable gender is identified as a factor, we can drop the factor levels that no longer use (such as "Female" and "Male" instead of "female" and "male")
```

Check whether the data cleaning had the desired effect
```{r check again}
table(mydata_cleaned$gender)
```




## Prediction with linear regressioin
### how to set up and interpret simple regression

Regression is all about predicting an outcome by knowing the value of predictor variables that are associated with the outcome.

You can set up a simple regression model by using the code below.
In the code we first specify an object where the results will be saved (mod1), then we specify the regression formula. In the formula, we start with specifying the outcome variable, what we are interested in predicting (shoe_size), then, after a ~ we specify the predictors. In simple regresison we only have one predictor (here this is height), but we could add more predictor variables, spearated with a + sign. In the end of the code we specify the data file where these variables originate from. Remember to use the cleaned dataset (mydata_cleaned).

```{r simple regression model}
mod1 <- lm(shoe_size ~ height, data = mydata_cleaned)
```

In simple regression, we identifies the underlying pattern of the data, by fitting a single straight line that is closest to all data points.

```{r, regression line}
plot(shoe_size ~ height, data = mydata_cleaned)
abline(mod1)
```

Regression provides a matematical equation (called the regression equation) with which you can predict the outcome by knowing the value of the predictors.

The regression equation is formalized as: Y = b0 + b1*X1, where Y is the predicted value of the outcome, b0 is the intercept, b1 is the regression coefficient for predictor 1, and X1 is the value of predictor 1.

```{r simple regression results}
mod1
```


This means that the regression equiation for predicting shoe size is:

shoe size = `r round(mod1[[1]][1], 2)` + `r round(mod1[[1]][2], 2)` * height

that is, for a person who is 170 cm tall, the predicted shoe size is calcluated this way:

`r round(mod1[[1]][1], 2)` + `r round(mod1[[1]][2], 2)` * 170 = `r round(mod1[[1]][1], 2) + (round(mod1[[1]][2], 2) * 170)`

You don't have to do the calculations by hand, you can get the predicted values by using the predict() function.

The predictors have to have the same variable name as in the regression formula, and they need to be in a dataframe

```{r predicted values}
height = c(150, 160, 170, 180, 190)
height_df = as.data.frame(height)
predictions = predict(mod1, newdata = height_df)
height_df_with_predicted = cbind(height_df, predictions)
height_df_with_predicted
```

Predicted values all fall on the regression line

```{r predictions on regression line}
plot(shoe_size ~ height, data = mydata_cleaned)
abline(mod1)
points(height_df_with_predicted, col = "red", pch = 19, cex = 2)
```



## How good is my model

### How to measure prediction efficiency?

You can measure how effective your model is by measureing the difference between the actual outcome values and the predicted values. We call this residual error in regression.

The residual error for each observed shoe size can be seen on this plot (this will only work if you ran the code in the top of the script containing the error_plotter() custom function). This code is only for visualization purposes.

```{r plot residual error}
error_plotter(mod1, col = "blue")
```

You can simply add up all the residual error (the length of these lines), and get a good measure of the overall efficiency of your model. This is called the residual absolute difference (RAD). However, this value is rarely used. More common is the residual sum of squared differences (RSS).

```{r RSS}
RAD = sum(abs(mydata_cleaned$shoe_size - predict(mod1)))
RAD

RSS = sum((mydata_cleaned$shoe_size - predict(mod1))^2)
RSS
```

### Is the predictor useful?

To establish how much benefit did we get by taking into account the predictor, we can compare the residual error when using out best guess (mean) without taking into account the predictor, with the residual error when the predictor is taken into account.

Below you can find regression model where we only use the mean of the outcome variable to predict the outcome value.

We can calculate the sum of squared differences the same way as before, but for the model without any predictors, we call this the total sum of squared differences (TSS).

```{r TSS}
mod_mean <- lm(shoe_size ~ 1, data = mydata_cleaned)

error_plotter(mod_mean, col = "red", x_var = "height") # visualize error

TSS = sum((mydata_cleaned$shoe_size - predict(mod_mean))^2)
TSS
```




The total amount of information gained about the variability of the outcome is shown by the R squared statistic (R^2).

```{r R squared}
R2 = 1-(RSS/TSS)
R2
```

This means that by using the regression model, we are able to explain `r paste(round(R2, 4)*100, "%", sep = "")` of the variability in the outcome.

R^2 = 1 means all variablility of the outcome is perfectly predicted by the predictor(s)

R^2 = 0 means no variablility  of the outcome is predicted by the predictor(s)

### Is the model with the predictor significantly better than a model without the predictor?

You can do an anova to find out, comparing the amount of variance explained by the two models.

```{r anova}
anova(mod_mean, mod1)
```

Or, you can get all this information and more from the model summary

```{r summary}
summary(mod1)
```

The confidence interval of the regression coefficient is given by the confint() function

```{r confidence interval}
confint(mod1)
```

You can also plot the confidence interval of the prediction

```{r plot confidence interval}
ggplot(mydata_cleaned, aes(x = height, y = shoe_size))+
  geom_point()+
  geom_smooth(method='lm',formula=y~x)
```


