---
title: "Exercise 12 - Multiple regression"
author: "Zoltan Kekecs"
date: "20 november 2018"
output:
  word_document:
    toc: yes
  pdf_document:
    number_sections: yes
    toc: yes
  html_document:
    number_sections: yes
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T, tidy.opts=list(width.cutoff=60), tidy=TRUE)
```

\pagebreak

# Abstract

Ennek a gyakorlatnak az a celja hogy az egyszeru regressziorol szerzett tudast altalanositsuk olyan esetekre, ahol tobb prediktor (bejoslo valtozo) is szerepel a modellben.

Ennek a dokumentumnak a legfrissebb valtozatat megtalalod itt:



# Data management and descriptive statistics

## Loading packages

You will need to load the following packages for this exercise:

```{r packages, message=FALSE}
library(psych) # for describe
library(lm.beta) # for lm.beta
library(car) # for scatter3d
library(ggplot2) # for ggplot
library(rgl) # for scatter3d
```



## Load data about housing prices in King County, USA 

In this exercise we will predict the price of apartments and houses. 

We use a dataset from Kaggle containing data about housing prices and variables that may be used to predict housing prices. The data is about accomodations in King County, USA (Seattle and sorrounding area).

We only use a portion of the full dataset now containing information about N = 200 accomodations.

You can load the data with the following code

```{r load data, message=FALSE}
# data from github/kekecsz/PSYP13_Data_analysis_class-2018/master/data_house_small_sub.csv. 
data_house = read.csv("https://bit.ly/2DpwKOr")
```

## Check the dataset

You should always check the dataset for coding errors or data that does not make sense.

View data in the data viewer tool 
```{r view data, eval=FALSE}
View(data_house)
```

Display simple descriptive statistics and plots.

We are going to predict price of the apartment using the variables sqft_living (the square footage of the living area), and grade (overall grade given to the housing unit, based on King County grading system), so lets focus on these variables.

Later we are also going to use a categorical variable, has_basement (whether the apartment has a basement or not) as well.

```{r check data, eval = F}
describe(data_house)
hist(data_house$price, breaks = 30)
hist(data_house$sqft_living, breaks = 30)
hist(data_house$grade, breaks = 30)

# scatterplot
plot(price ~ sqft_living, data = data_house)
plot(price ~ grade, data = data_house)

table(data_house$has_basement)
plot(data_house$price ~ data_house$has_basement)
```

# Multiple regression

## Fitting the regression model

We fit a regression model with multiple predictors: sqft_living and grade. In the formula, the predictors are separated by a + sign.


```{r regression model}
mod_house1 = lm(price ~ sqft_living + grade, data = data_house)
```

The regression equation is displayed just like in the case of simple regression

```{r regression equation}
mod_house1
```


It is not trivial to visualize the regression equation in multiple regression. You can plot every simple regression separately, but that is not an accurate depiction of the prediction using the model.

```{r plot regression lines}
plot(price ~ sqft_living, data = data_house)
abline(lm(price ~ sqft_living, data = data_house))
plot(price ~ grade, data = data_house)
abline(lm(price ~ grade, data = data_house))
```

Alternatively, you can use a 3 dimensional plot to visualize the regression plane.

```{r plot regression plane, eval = F}
# plot the regression plane (3D scatterplot with regression plane)
# scatter3d(price ~ sqft_living + grade, data = data_house)

```

## Prediction

Again, we can ask for predictions for specific values of predictors, but we need to specify all predictor values (in this case, both sqft_living and grade of the apartment) to get a prediction.

Remember that you need to provide the predictors in a dataframe with the predictors having the same variable name as in the model formula.

```{r prediction for new data points}
sqft_living = c(600, 600, 1100, 1100)
grade = c(6, 9, 6, 9)
newdata_to_predict = as.data.frame(cbind(sqft_living, grade))
predicted_price = predict(mod_house1, newdata = newdata_to_predict)

cbind(newdata_to_predict, predicted_price)
```

# What to report in a publication

In a publication (and in the home assignment) you will need to report the following information:

First of all, you will have to specify the regression model you built. For example: 

"In a linar regression model we predicted housing price (in USD) with square footage of living area (in ft) and King County housing grade as predictors."

Next you will have to indicate the effectiveness of the model. You can do this by after a text summary of the results, giving information about the F-test of the whole model, specifically, the F value, the degrees of freedom (note that there are two degrees of freedom for the F test), and the p-value. You can find all this information in the model summary. Also provide information about the model fit using the adjusted R squared from the model summary and the AIC values provided by the AIC() function.

Don't forget to use APA guidelines when determing how to report these statistics and how many decimal places to report (2 decimals for every number except for p values, which should be reported up to 3 decimals).

```{r model summary}
sm = summary(mod_house1)
sm

AIC(mod_house1)
```

"The multiple regression model was significantly better than the null model, explaining `r round(sm$adj.r.squared, 4)*100`% of the variance in housing price (F `r paste("(", round(sm$fstatistic[2]), ", ", round(sm$fstatistic[3]), ")", sep = "")` =  `r round(sm$fstatistic[1], 2)`, `r if(round(pf(sm$fstatistic[1],sm$fstatistic[2],sm$fstatistic[3],lower.tail=F), 3) == 0){"p < .001"} else {paste("p = ", round(pf(sm$fstatistic[1],sm$fstatistic[2],sm$fstatistic[3],lower.tail=F), 3), sep = ")")}`, Adj. R^2 = `r round(sm$adj.r.squared, 2)`, AIC = `r round(AIC(mod_house1), 2)`)."


Furthermore, you will have to provide information about the regression equation and the predictors' added value to the model. You can do this by creating a table with the following information:

Regression coefficients with confidence intervals, and standardized beta values for each predictor, together with the p-values of the t-test.

The regression coefficients and p-values can be found in the model summary, and the confidence interavlas and std. betas can be computed by applying the confint() and lm.beta() functions on the model object. (the lm.beta package is needed for the lm.beta() function)
```{r coef functions, eval = F}
confint(mod_house1)
lm.beta(mod_house1)
```

The final table should look something like this:

```{r coef table, echo = F}
sm_p_values = as.character(round(sm$coefficients[,4], 3))
sm_p_values[sm_p_values != "0" & sm_p_values != "1"] = substr(sm_p_values[sm_p_values != "0" & sm_p_values != "1"], 2, nchar(sm_p_values[sm_p_values != "0" & sm_p_values != "1"]))
sm_p_values[sm_p_values == "0"] = "<.001"


sm_table = cbind(as.data.frame(round(cbind(coef(mod_house1), confint(mod_house1), c(0, lm.beta(mod_house1)$standardized.coefficients[c(2,3)])), 2)), sm_p_values)
names(sm_table) = c("b", "95%CI lb", "95%CI ub", "Std.Beta", "p-value")
sm_table["(Intercept)","Std.Beta"] = "0"
```

```{r APA table, echo=F}
sm_table
```

You should refer to your course book (Chapter 15 - Navarro D. (2015). Learning statistics with R: A tutorial for psychology students and other beginners (5th ed.). http://www.compcogscisydney.com/learning-statistics-with-r.html) for the interpretation of the data reported above.


# Build better models

Experiment with different models based on your theories about what could influence housing prices.

Try to increase the adjusted R^2 above 52%.
If you want to get access to the whole dataset or get ideas on which model works best, go to Kaggle, check out the top kernels, and download the data.
https://www.kaggle.com/harlfoxem/housesalesprediction/activity


## Categorical predictor

Categorical variables can be included in models just like continuous variables. Here, we include the variable has_basement as a predictor, which is a categorical variable that has two levels: 'has basement' and 'no basement'. In this case, the intercept can be interpreted as the predicted value for all continuous predictor values as 0, and the has_basement variable at its default level: 'has basement'. The regression coefficient for has_basement indicates how much price is predicted to change if the apartment has no basement compared to if it has basement.

```{r categorical predictor}
mod_cat = lm(price ~ sqft_living + grade + has_basement, data = data_house)

summary(mod_cat)
```


The default level (reference level) of categorical variables is the level earliest in the alphabet. For this reason, the reference level of the variable has_basement is "has basement". For more intuitive interpretation, it would make sense to change the reference level to "no basement", so that the model coefficient for this variable would be positive, and it would indicate how much price increase would a basement mean for the apartment sales.

This can be done with the relevel() function. We have to re-run the model for this change to take effect in the model object.


```{r relevel}
data_house$has_basement = relevel(data_house$has_basement, ref = "no basement")

mod_cat = lm(price ~ sqft_living + grade + has_basement, data = data_house)
summary(mod_cat)
```

Now it is apparent from the model summary that if an apartment has a basement, this means a `r  format(round(coef(mod_cat)["has_basementhas basement"]), digits = 2)` USD increase in price compared to apartments which do not have a basement (the reference level).

## Higher order terms

If you suspect that there is non-linear relationship between the outcome and some predictor, you can try to include a second or third order term.

For example, here we can see that the relationship of price and grade is not entirely linear.

```{r nonlinear relationship plot}
plot(price ~ grade, data = data_house)
```

So we build a model including the second order term of grade, to account for a quadratic relationsip.

Unless you know what you are doing, always add the first order term in the model as well, like here:

```{r higher order terms}
mod_house_quad <- lm(price ~ grade + I(grade^2), data = data_house)
summary(mod_house_quad)

ggplot(data_house, aes(x = grade, y = price))+
  geom_point()+
  geom_smooth(method='lm',formula=y~x+I(x^2))
```

## Interactions

A relationship of different predictors can also be modelled, if you suspect that the association of a predictor and the outcome might depend on the value of another predictor.

For example here we first build a model where we include the effect of geographic location (longitude and latitude) in the model (mod_house_geolocation), and next, we include the interaction of longitude and latitude in the model, because we suspect that these parameters might influence each others association with price.

```{r interaction term}
mod_house_geolocation = lm(price ~ sqft_living + grade + long + lat, data = data_house)
summary(mod_house_geolocation)

mod_house_geolocation_inter2 = lm(price ~ sqft_living + grade + long * lat, data = data_house)
summary(mod_house_geolocation_inter2)
```

Note that the adjusted R squared did not increase substancially due to the inclusion of the interaction term, so it might not be so useful to take into account the interaction, it might be enoug to take into account the main effects of longitude and latitude. This needs to be further evaluated with model comparison. See the exercise related to that.


